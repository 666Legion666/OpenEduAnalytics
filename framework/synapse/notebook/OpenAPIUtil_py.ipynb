{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from curses import meta\r\n",
        "from pyspark.sql.types import *\r\n",
        "import requests\r\n",
        "import pyspark.sql.functions as f\r\n",
        "import json\r\n",
        "import re\r\n",
        "\r\n",
        "class OpenAPIUtil:\r\n",
        "    \"\"\"\r\n",
        "    A Utility class to help processing transformations using Open API (Swagger).\r\n",
        "\r\n",
        "    Parameters:\r\n",
        "        1) swagger_url: URL to the OpenAPI Swaggern endpoint\r\n",
        "\r\n",
        "    Methods:\r\n",
        "        1) create_spark_schemas(): returns a dictionary of Spark schemas of all endpoints with entity name as the Key.\r\n",
        "        2) create_metadata(): returns list of dictionaries containing metadata of each field in every endpoint.\r\n",
        "        3) write_oea_metadata(destination_path): Writes out the OEA Metadata CSV file at the destination directory.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, swagger_url):\r\n",
        "        self.swagger_json = json.loads(requests.get(swagger_url).text)\r\n",
        "        self.metadata_headers = ['table_name', 'column_name', 'type', 'format', 'maxLength', 'required', 'items', '$ref', 'pseudonymization']\r\n",
        "        self.definitions = {}\r\n",
        "        self.metadata = {}\r\n",
        "        self.tables = []\r\n",
        "        self.schemas = {}\r\n",
        "        self.dependency_dict = {}\r\n",
        "        self.dependency_order = []\r\n",
        "        self.visited = {}\r\n",
        "\r\n",
        "    def get_reference(self, row):\r\n",
        "        if(row['type'] == 'array'):\r\n",
        "            reference = row['items']['$ref']\r\n",
        "        elif(row['$ref'] != None):\r\n",
        "           reference = row['$ref']\r\n",
        "        else:\r\n",
        "            return None\r\n",
        "        return reference.split('/')[-1].split('_')[-1]\r\n",
        "\r\n",
        "    def pluralize(self, noun):\r\n",
        "        if noun == 'person' : return 'people'\r\n",
        "        if noun == 'survey' : return 'surveys'\r\n",
        "        if re.search('[sxz]$', noun):\r\n",
        "            return re.sub('$', 'es', noun)\r\n",
        "        if re.search('y$', noun):\r\n",
        "            return re.sub('y$', 'ies', noun)\r\n",
        "        return noun + 's'\r\n",
        "\r\n",
        "    def get_data_type(self, dtype, format):\r\n",
        "        if(dtype == 'string'):\r\n",
        "            if(format == 'date'):\r\n",
        "                return DateType()\r\n",
        "            if(format == 'date-time'):\r\n",
        "                return TimestampType()\r\n",
        "            return StringType()\r\n",
        "        if(dtype == 'integer'):\r\n",
        "            return IntegerType()\r\n",
        "        if(dtype == 'number'):\r\n",
        "            return DecimalType()\r\n",
        "        if(dtype == 'boolean'):\r\n",
        "            return BooleanType()\r\n",
        "\r\n",
        "    def create_definitions(self):\r\n",
        "        for entity in self.swagger_json['definitions']:\r\n",
        "            properties = self.swagger_json['definitions'][entity]['properties']\r\n",
        "            table_name = entity.split('_')[-1]\r\n",
        "            table_schema = {}\r\n",
        "\r\n",
        "            for prop in properties:\r\n",
        "                if 'description' in properties[prop].keys():\r\n",
        "                    properties[prop].pop('description')\r\n",
        "                field_info = properties[prop]\r\n",
        "                if 'required' in self.swagger_json['definitions'][entity].keys():\r\n",
        "                    field_info['required'] = True if prop in self.swagger_json['definitions'][entity]['required'] else False\r\n",
        "                else:\r\n",
        "                    field_info['required'] = False\r\n",
        "                field_info['table_name'] = entity.split('_')[-1]\r\n",
        "                field_info['column_name'] = prop\r\n",
        "                if 'x-Ed-Fi-pseudonymization' in field_info:\r\n",
        "                    field_info['pseudonymization'] = field_info['x-Ed-Fi-pseudonymization']\r\n",
        "                    field_info.pop('x-Ed-Fi-pseudonymization')\r\n",
        "                for header in [x for x in self.metadata_headers if x not in field_info] : field_info[header] = None\r\n",
        "                table_schema[prop] = field_info\r\n",
        "\r\n",
        "            self.definitions[table_name] = table_schema\r\n",
        "        self.tables = [x for x in self.definitions.keys()]\r\n",
        "\r\n",
        "    def create_metadata(self):\r\n",
        "        if(len(self.schemas) == 0):\r\n",
        "            self.create_spark_schemas()\r\n",
        "        for table_name in self.dependency_order:\r\n",
        "            table_metadata = []\r\n",
        "            for col_name in self.definitions[table_name]:\r\n",
        "                col_schema = self.definitions[table_name][col_name]\r\n",
        "                key = self.pluralize(table_name)\r\n",
        "\r\n",
        "                if 'x-Ed-Fi-fields-to-pluck' in col_schema and col_schema['x-Ed-Fi-fields-to-pluck'] != [\"*\"]:\r\n",
        "                    referenced_table = self.get_reference(col_schema)\r\n",
        "                    table_metadata += [x for x in self.metadata[self.pluralize(referenced_table)] if x[0] in col_schema['x-Ed-Fi-fields-to-pluck']]\r\n",
        "\r\n",
        "                elif 'x-Ed-Fi-explode' in col_schema and col_schema['x-Ed-Fi-explode']:\r\n",
        "                    referenced_table = self.get_reference(col_schema)\r\n",
        "                    table_metadata += self.metadata[self.pluralize(referenced_table)]\r\n",
        "\r\n",
        "                else:\r\n",
        "                    op = self.definitions[table_name][col_name]['pseudonymization']\r\n",
        "                    if op == None: op = 'no-op'\r\n",
        "                    table_metadata.append([col_name, self.schemas[key][col_name].dataType.typeName(), op])\r\n",
        "            self.metadata[self.pluralize(table_name)] = table_metadata\r\n",
        "        return self.metadata\r\n",
        "\r\n",
        "    def write_oea_metadata(self, destination_path):\r\n",
        "        if(self.metadata == []):\r\n",
        "            self.create_metadata()\r\n",
        "        oea_metadata = []\r\n",
        "        for table_name in self.metadata:\r\n",
        "            oea_metadata.append([table_name, None, None, None])\r\n",
        "            for col_metadata in self.metadata[table_name]:\r\n",
        "                oea_metadata.append([None] + col_metadata)\r\n",
        "        metadata_df = spark.createDataFrame(oea_metadata, ['Entity Name','Attribute Name','Attribute Data Type','Pseudonymization'])\r\n",
        "        metadata_df.write.format('csv').save(destination_path)\r\n",
        "\r\n",
        "    def create_dependency_dict(self):\r\n",
        "        for table_name in self.definitions:\r\n",
        "            for column_name in self.definitions[table_name]:\r\n",
        "                column_info = self.definitions[table_name][column_name]\r\n",
        "                referenced_table = self.get_reference(column_info)\r\n",
        "                if(referenced_table is None):\r\n",
        "                    continue\r\n",
        "                if table_name not in self.dependency_dict:\r\n",
        "                    self.dependency_dict[table_name] = [referenced_table]\r\n",
        "                elif referenced_table not in self.dependency_dict[table_name]:\r\n",
        "                    self.dependency_dict[table_name].append(referenced_table)\r\n",
        "\r\n",
        "    def dfs(self, table_name):\r\n",
        "        self.visited[table_name] = True\r\n",
        "        if table_name not in self.dependency_dict:\r\n",
        "            self.dependency_order.append(table_name)\r\n",
        "            return\r\n",
        "\r\n",
        "        for dependent_table in self.dependency_dict[table_name]:\r\n",
        "            if(self.visited[dependent_table] is False):\r\n",
        "                self.dfs(dependent_table)\r\n",
        "            if(self.visited[dependent_table] is False):\r\n",
        "                self.dependency_order.append(dependent_table)\r\n",
        "\r\n",
        "        self.dependency_order.append(table_name)\r\n",
        "\r\n",
        "    def create_dependency_order(self):\r\n",
        "        for table_name in self.tables:\r\n",
        "            self.visited[table_name] = False\r\n",
        "        for table_name in self.tables:\r\n",
        "            if(self.visited[table_name] is False):\r\n",
        "                self.dfs(table_name)\r\n",
        "\r\n",
        "    def create_spark_schemas_from_definitions(self):\r\n",
        "        for entity in self.dependency_order:\r\n",
        "            table_schema = self.definitions[entity]\r\n",
        "            spark_schema = []\r\n",
        "            for col_name in table_schema:\r\n",
        "                col_metadata = {}\r\n",
        "                if('pseudonymization' in table_schema[col_name]): col_metadata['pseudonymization'] = table_schema[col_name]['pseudonymization']\r\n",
        "                referenced_table = self.get_reference(table_schema[col_name])\r\n",
        "                if table_schema[col_name]['type'] == 'array':\r\n",
        "                    datatype = ArrayType(self.schemas[self.pluralize(referenced_table)])\r\n",
        "                    col_metadata['x-Ed-Fi-explode'] = table_schema[col_name]['x-Ed-Fi-explode']\r\n",
        "                elif table_schema[col_name]['$ref'] != None:\r\n",
        "                    datatype = self.schemas[self.pluralize(referenced_table)]\r\n",
        "                    if('x-Ed-Fi-fields-to-pluck' in table_schema[col_name]):\r\n",
        "                        col_metadata['x-Ed-Fi-fields-to-pluck'] = table_schema[col_name]['x-Ed-Fi-fields-to-pluck']\r\n",
        "                else:\r\n",
        "                    datatype = self.get_data_type(table_schema[col_name]['type'], table_schema[col_name]['format'])\r\n",
        "                col_spark_schema = StructField(col_name, datatype, not(table_schema[col_name]['required']))\r\n",
        "                col_spark_schema.metadata = col_metadata\r\n",
        "                spark_schema.append(col_spark_schema)\r\n",
        "            self.schemas[self.pluralize(entity)] = StructType(spark_schema)\r\n",
        "\r\n",
        "    def create_spark_schemas(self):\r\n",
        "        if(len(self.schemas) == 0):\r\n",
        "            self.create_definitions()\r\n",
        "            self.create_dependency_dict()\r\n",
        "            self.create_dependency_order()\r\n",
        "            self.create_spark_schemas_from_definitions()\r\n",
        "        return self.schemas\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}